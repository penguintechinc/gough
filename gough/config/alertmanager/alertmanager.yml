# AlertManager Configuration for Gough HA
# Enterprise-grade alerting with PagerDuty, Slack, and email integration
# Designed for 99.9% uptime monitoring and incident response

global:
  # SMTP configuration for email alerts
  smtp_smarthost: '${SMTP_HOST}:${SMTP_PORT}'
  smtp_from: 'alerts@gough.local'
  smtp_auth_username: '${SMTP_USERNAME}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true
  
  # Slack webhook URL
  slack_api_url: '${SLACK_WEBHOOK_URL}'
  
  # PagerDuty integration
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'
  
  # Global alert resolution timeout
  resolve_timeout: 5m

# Templates for custom alert formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route configuration
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: critical-alerts
      group_wait: 0s
      repeat_interval: 5m

    # Database alerts
    - match:
        category: database
      receiver: database-team
      group_interval: 5m

    # MaaS specific alerts
    - match:
        category: maas
      receiver: infrastructure-team
      group_interval: 2m

    # FleetDM alerts
    - match:
        category: fleet
      receiver: security-team
      group_interval: 5m

    # Container alerts
    - match:
        category: containers
      receiver: devops-team
      group_interval: 10m

    # Logging infrastructure alerts
    - match:
        category: logging
      receiver: logging-team
      group_interval: 5m

# Inhibition rules to prevent alert spam
inhibit_rules:
  # Silence non-critical alerts if critical alerts are firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']

  # Silence individual service alerts if the whole node is down
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '(High.*Usage|.*ServiceDown)'
    equal: ['instance']

# Receiver configurations
receivers:
  # Default webhook receiver
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://localhost:5001/'
        send_resolved: true

  # Critical alerts - multiple channels
  - name: critical-alerts
    email_configs:
      - to: 'ops-team@example.com'
        subject: '[CRITICAL] Gough Hypervisor Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels:
          {{ range .Labels.SortedPairs }}  {{ .Name }}: {{ .Value }}
          {{ end }}
          {{ end }}
        html: |
          <!DOCTYPE html>
          <html>
          <head><title>Critical Alert</title></head>
          <body>
          <h2 style="color: red;">Critical Alert - Immediate Action Required</h2>
          {{ range .Alerts }}
          <h3>{{ .Annotations.summary }}</h3>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          <p><strong>Severity:</strong> {{ .Labels.severity }}</p>
          <p><strong>Service:</strong> {{ .Labels.service }}</p>
          <p><strong>Time:</strong> {{ .StartsAt.Format "2006-01-02 15:04:05" }}</p>
          <hr>
          {{ end }}
          </body>
          </html>
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#gough-critical'
        title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Service:* {{ .Labels.service }}
          {{ end }}
        color: 'danger'
        send_resolved: true

  # Database team alerts
  - name: database-team
    email_configs:
      - to: 'database-team@example.com'
        subject: '[DB Alert] {{ .GroupLabels.alertname }}'
        body: |
          Database Alert Triggered:
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Database: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#gough-database'
        title: 'Database Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Database:* {{ .Labels.service }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ end }}
        color: 'warning'

  # Infrastructure team (MaaS alerts)
  - name: infrastructure-team
    email_configs:
      - to: 'infrastructure@example.com'
        subject: '[Infrastructure] MaaS Alert: {{ .GroupLabels.alertname }}'
        body: |
          MaaS Infrastructure Alert:
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#gough-infrastructure'
        title: 'MaaS Alert: {{ .GroupLabels.alertname }}'
        color: 'warning'

  # Security team (FleetDM alerts)
  - name: security-team
    email_configs:
      - to: 'security-team@example.com'
        subject: '[Security] FleetDM Alert: {{ .GroupLabels.alertname }}'
        body: |
          FleetDM Security Alert:
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Fleet Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#gough-security'
        title: 'FleetDM Alert: {{ .GroupLabels.alertname }}'
        color: 'warning'

  # DevOps team (Container alerts)
  - name: devops-team
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#gough-devops'
        title: 'Container Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Container:* {{ .Labels.name }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ end }}
        color: 'warning'

  # Logging team
  - name: logging-team
    email_configs:
      - to: 'logging-team@example.com'
        subject: '[Logging] ELK Stack Alert: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#gough-logging'
        title: 'Logging Alert: {{ .GroupLabels.alertname }}'
        color: 'warning'